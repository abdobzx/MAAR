# üöÄ Guide d'utilisation du syst√®me MAR RAG avec Ollama

## ‚úÖ √âtat actuel du syst√®me

Ton syst√®me RAG est **OP√âRATIONNEL** ! Voici ce qui fonctionne :

### üîß Services actifs
- **Service RAG** : `http://localhost:8001`
- **Documentation** : `http://localhost:8001/docs`
- **Ollama LLM** : `http://localhost:11434`
- **Mod√®le** : `llama3.2:3b` (2GB, optimis√©)

## üß™ Comment tester le syst√®me

### 1. Via l'interface web (recommand√©)
Ouvre ton navigateur : `http://localhost:8001/docs`
- Clique sur `POST /api/v1/query`
- Clique sur "Try it out"
- √âcris ta question dans le champ `question`
- Clique sur "Execute"

### 2. Via curl (terminal)
```bash
# Test simple
curl -X POST http://localhost:8001/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Qu'\''est-ce qu'\''un syst√®me RAG?"}'

# V√©rification de sant√©
curl http://localhost:8001/health
```

### 3. Via Python
```python
import requests

response = requests.post(
    "http://localhost:8001/api/v1/query",
    json={"question": "Comment fonctionne un syst√®me RAG?"}
)
print(response.json()["answer"])
```

## üìù Exemples de questions √† tester

### Questions simples (r√©ponses rapides ~5-15s)
- "Qu'est-ce qu'un syst√®me RAG?"
- "Explique FastAPI en 2 phrases"
- "Comment fonctionne Ollama?"

### Questions techniques (r√©ponses plus lentes ~30-60s)
- "Comment cr√©er une API REST avec FastAPI?"
- "Explique l'architecture microservices"
- "Quels sont les avantages des embeddings vectoriels?"

### Questions sur ton projet MAR
- "Comment structurer un syst√®me RAG multi-agents?"
- "Quelles technologies utiliser pour un syst√®me de recherche s√©mantique?"
- "Comment optimiser les performances d'un syst√®me RAG?"

## ‚ö° Optimisations possibles

### Si les r√©ponses sont trop lentes:
1. **Utilise des questions plus courtes**
2. **Augmente la RAM disponible pour Ollama**
3. **Utilise un mod√®le plus petit** (mais moins performant)

### Pour am√©liorer les r√©ponses:
1. **Ajoute plus de contexte** dans les questions
2. **Utilise des prompts plus sp√©cifiques**
3. **Int√®gre une base de connaissances**

## üîÑ Comment red√©marrer le syst√®me

```bash
# Red√©marrer tout
cd /Users/abderrahman/Documents/MAR
source .venv/bin/activate

# Terminal 1: Ollama
ollama serve

# Terminal 2: Service RAG
python rag_simple_ollama.py
```

## üÜï Prochaines √©tapes

1. **Base de donn√©es** : Ajouter PostgreSQL pour persister les donn√©es
2. **Recherche vectorielle** : Int√©grer Qdrant/Chroma pour la recherche s√©mantique
3. **Agents sp√©cialis√©s** : Cr√©er des agents pour diff√©rents domaines
4. **Interface utilisateur** : D√©velopper une interface web moderne
5. **Monitoring** : Ajouter des m√©triques et logs

## üêõ R√©solution des probl√®mes

### Service ne r√©pond pas
```bash
curl http://localhost:8001/health
# Si √ßa ne marche pas : red√©marrer le service
```

### Ollama timeout
```bash
# V√©rifier Ollama
curl http://localhost:11434/api/version
# Si √ßa ne marche pas : relancer ollama serve
```

### Questions trop lentes
- Utilise des questions plus courtes
- √âvite les questions tr√®s complexes
- Augmente le timeout dans le code si n√©cessaire

## ‚ú® Ton syst√®me est maintenant pr√™t !

Tu as un **vrai syst√®me RAG fonctionnel** avec :
- ‚úÖ API REST FastAPI
- ‚úÖ LLM Ollama (llama3.2:3b)
- ‚úÖ Interface de test Swagger
- ‚úÖ Documentation compl√®te
- ‚úÖ Temps de r√©ponse acceptable

**Plus besoin d'attendre 4650 secondes !** üéâ
